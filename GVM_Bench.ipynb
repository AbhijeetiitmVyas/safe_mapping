{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active-Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "device = \"cuda:1\"\n",
    "# c = np.random.randn(3,2)\n",
    "# c=np.clip(a_min=-2.0,a_max=2.0,a=c)\n",
    "def labels(x,c):\n",
    "    \n",
    "    d=c-x\n",
    "    d=np.clip(a_min=-0.5,a_max=0.5,a=d)-d\n",
    "    \n",
    "    for i in d:\n",
    "        if i[0]==0 and i[1]==0:\n",
    "             return(1)\n",
    "    else: return(0.2)\n",
    "    \n",
    "def labels_diff_shape(x,c):\n",
    "    \n",
    "    d=c-x\n",
    "    d1=np.clip(a_min=-0.5,a_max=0.5,a=d)-d\n",
    "    d1_prox = []\n",
    "    d2=np.clip(a_min=-0.5,a_max=0.9,a=d)-d\n",
    "    d2_prox = []\n",
    "\n",
    "    for i in d1:\n",
    "        if i[0]==0 and i[1]==0:\n",
    "             d1_prox.append(1)\n",
    "        else: d1_prox.append(0)\n",
    "    for i in d2:\n",
    "        if i[0]==0 and i[1]==0:\n",
    "             d2_prox.append(1)\n",
    "        else: d2_prox.append(0)\n",
    "\n",
    "    if (d1_prox[0]==1 and d2_prox[0]==1) or (d1_prox[1]==1) or (d2_prox[0]==1):\n",
    "        return(1)\n",
    "    else: return(0.2)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create True Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_MIN, X_MAX, Y_MIN, Y_MAX = -2.5, 2.5, -2.5, 2.5\n",
    "TABLE_X_LENGTH, TABLE_Y_LENGTH = 1, 1\n",
    "SOFA_X_LENGTH, SOFA_Y_LENGTH = 1, 1\n",
    "map_scale = 32\n",
    "\n",
    "def random_table_sofa_centers(n_tables, n_sofas):\n",
    "    \"\"\"\n",
    "    Generate random table center locations within the bounds of the room and not\n",
    "    overlapping with each other.\n",
    "\n",
    "    :param n_tables: The number of table centers to generate\n",
    "    :return: The table centers in a list of [x, y] pairs\n",
    "    \"\"\"\n",
    "    def is_overlap(table_centers, sofa_centers, new_x, new_y, new_x_len, new_y_len):\n",
    "        overlap = False\n",
    "        for x, y in table_centers:\n",
    "            if (abs(x - new_x) < (TABLE_X_LENGTH + new_x_len) / 2 and \n",
    "                abs(y - new_y) < (TABLE_Y_LENGTH + new_y_len) / 2):\n",
    "                overlap = True\n",
    "        for x, y in sofa_centers:\n",
    "            if (abs(x - new_x) < (SOFA_X_LENGTH + new_x_len) / 2 and \n",
    "                abs(y - new_y) < (SOFA_Y_LENGTH + new_y_len) / 2):\n",
    "                overlap = True\n",
    "        return overlap\n",
    "\n",
    "    table_centers, sofa_centers = [], []\n",
    "    for _ in range(n_tables):\n",
    "        new_x = X_MIN + TABLE_X_LENGTH / 2 + np.random.rand() * (X_MAX - X_MIN - TABLE_X_LENGTH)\n",
    "        new_y = Y_MIN + TABLE_Y_LENGTH / 2 + np.random.rand() * (Y_MAX - Y_MIN - TABLE_Y_LENGTH)\n",
    "        while is_overlap(table_centers, sofa_centers, new_x, new_y, TABLE_X_LENGTH, TABLE_Y_LENGTH):\n",
    "            new_x = X_MIN + TABLE_X_LENGTH / 2 + np.random.rand() * (X_MAX - X_MIN - TABLE_X_LENGTH)\n",
    "            new_y = Y_MIN + TABLE_Y_LENGTH / 2 + np.random.rand() * (Y_MAX - Y_MIN - TABLE_Y_LENGTH)\n",
    "        table_centers.append([new_x, new_y])\n",
    "    for _ in range(n_sofas):\n",
    "        new_x = X_MIN + SOFA_X_LENGTH / 2 + np.random.rand() * (X_MAX - X_MIN - SOFA_X_LENGTH)\n",
    "        new_y = Y_MIN + SOFA_Y_LENGTH / 2 + np.random.rand() * (Y_MAX - Y_MIN - SOFA_Y_LENGTH)\n",
    "        while is_overlap(table_centers, sofa_centers, new_x, new_y, SOFA_X_LENGTH, SOFA_Y_LENGTH):\n",
    "            new_x = X_MIN + SOFA_X_LENGTH / 2 + np.random.rand() * (X_MAX - X_MIN - SOFA_X_LENGTH)\n",
    "            new_y = Y_MIN + SOFA_Y_LENGTH / 2 + np.random.rand() * (Y_MAX - Y_MIN - SOFA_Y_LENGTH)\n",
    "        sofa_centers.append([new_x, new_y])\n",
    "    return table_centers, sofa_centers\n",
    "room_center=[]\n",
    "for i in range(400):\n",
    "    temp = random_table_sofa_centers(5,0)\n",
    "    room_center.append(temp[0])\n",
    "c_rooms = np.stack(room_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Images for input\n",
    "### Using ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc=np.random.randint(low=-150,high=150,size=(400,30,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #input images from labeller\n",
    "# imgs_in=[]\n",
    "# for i,room in enumerate(xc):\n",
    "#     temp = []\n",
    "#     for j in room:\n",
    "#         temp_img=[]\n",
    "#         temp_x = np.arange(j[0]-100,j[0]+100,5)\n",
    "#         temp_y = np.arange(j[1]-100,j[1]+100,5)\n",
    "#         x,y=np.meshgrid(temp_x,temp_y)\n",
    "#         for k in np.append(x.reshape(1,1600).T,y.reshape(1,1600).T,1):\n",
    "#             temp_img.append(labels(k/100,c_rooms[i]))\n",
    "#         temp_img=np.array(temp_img)\n",
    "#         temp.append(temp_img.reshape(40,40))\n",
    "#     imgs_in.append(temp)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_image_from_truth(true_map,xy):\n",
    "    xy[0]+=2.5\n",
    "    xy[1]+=2.5\n",
    "    xy[0]/=0.05\n",
    "    xy[1]/=0.05  \n",
    "    a = np.int(np.floor(xy[0]))\n",
    "    b = np.int(np.floor(xy[1]))\n",
    "    return(true_map[a-20:a+20,b-20:b+20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Padded input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For GVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_images(image,xy):\n",
    "    c_x = xy[1]/0.05+50\n",
    "    c_y = xy[0]/0.05+50\n",
    "    x_0 =int(c_x%10)\n",
    "    y_0 = int(c_y%10)\n",
    "    image_new = np.zeros((2,50,50))\n",
    "    image_new[0,x_0:x_0+40,y_0:y_0+40] = 1\n",
    "    image_new[1,x_0:x_0+40,y_0:y_0+40] = image\n",
    "    return(image_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create True Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_true_map(centres):\n",
    "    #select uniformly\n",
    "    xm=np.arange(-2.5,2.5,0.05)\n",
    "    ym=np.arange(-2.5,2.5,0.05)\n",
    "    xm,ym = np.meshgrid(xm,ym)\n",
    "    map_samp = np.append(xm.reshape(1,10000).T,ym.reshape(1,10000).T,1)\n",
    "    #label Uniform Points\n",
    "    true_map = []\n",
    "    for j in range(10000):\n",
    "        true_map.append(labels(map_samp[j],centres))\n",
    "    return(np.array(true_map).reshape(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_maps = []\n",
    "for i in c_rooms:\n",
    "    true_maps.append(create_true_map(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in=[]\n",
    "for i,room in enumerate(xc):\n",
    "    temp = []\n",
    "    for j in room:\n",
    "        temp_img=inp_image_from_truth(true_maps[i],j/100)\n",
    "        temp.append(temp_img)\n",
    "    imgs_in.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot True Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61c8c65a58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61cb073898>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(true_maps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pad input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in_1 = deepcopy(imgs_in)\n",
    "for rooms in range(400):\n",
    "    for j,image in enumerate(imgs_in[rooms]):\n",
    "        imgs_in_1[rooms][j] = pad_images(image,xc[rooms][j]/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.8, 57.6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc[0][10][0]/5+50,xc[0][10][1]/5+50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61c8aee860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61cb073cf8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_in[0][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61c89f6c18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61c8ad0390>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_in[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61c89d9cc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61c8a942e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_in_1[0][4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor(obj):\n",
    "    return torch.tensor(obj, device=device,dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GVM(nn.Module):\n",
    "\n",
    "    def __init__(self, D=20, grid=(10, 10), write_size=(5,5), grid_scale=2, \n",
    "                 mins=(-2.5, -2.5), pixel_scale=20):\n",
    "        \n",
    "        super(GVM, self).__init__()\n",
    "        self.D = D\n",
    "        self.grid = grid\n",
    "        self.write_size = write_size\n",
    "        self.write_size_flat = write_size[0] * write_size[1] * D\n",
    "        self.grid_scale = grid_scale  # number of position units per grid cells \n",
    "        self.pixel_scale = pixel_scale  # number of pixels in a position unit\n",
    "        self.mins = mins\n",
    "         \n",
    "        # Downsampler\n",
    "        self.img_write_encode = nn.Sequential(  # 50x50\n",
    "            nn.Conv2d(2, 8, 3),    # 48x48\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 3),   # 46x46\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),       # 23x23\n",
    "            nn.Conv2d(16, 16, 3),  # 21x21\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3),       # 7x7\n",
    "            nn.Conv2d(16, 16, 3),  # 5x5\n",
    "        )\n",
    "        self.write_combine = nn.Conv2d(D + 1 + 16, D + 16, 3, padding=1)\n",
    "        self.write_final = nn.Conv2d(D + 16, D, 1)\n",
    "        \n",
    "#         self.write1 = nn.Linear(self.write_size_flat + 64, 256)\n",
    "#         self.write2 = nn.Linear(256, 256)\n",
    "#         self.write3 = nn.Linear(256, self.write_size_flat)\n",
    "#         self.init_mem = nn.Parameter(torch.randn(D, grid[0], grid[1]).type(torch.FloatTensor), requires_grad=True)\n",
    "        #learnable initial hidden state\n",
    "        \n",
    "        #latest evolved hidden state\n",
    "        self.embedding = None\n",
    "        \n",
    "        self.images = []\n",
    "        #(x,y) - for all points - to be used as embedding\n",
    "        self.xy_current = []\n",
    "        \n",
    "        #(x,y) - at probe points -to be used as classification \n",
    "        self.dropout = nn.Dropout(0.2) \n",
    "        \n",
    "        self.map_decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(D + 1, 16, 5, stride=3, padding=2),  # b, 16, 28, 28\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=2),  # b, 8, 53, 53\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=3)  # b, 1, 100, 100\n",
    "        )\n",
    "        \n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),weight_decay = 0.0001,  lr=0.001)\n",
    "\n",
    "        self.to(device)\n",
    "        self.prev_room_data = []\n",
    "        self.counter_label_list = []\n",
    "        \n",
    "#     def forward_write(self, grid_mem, xy, img):\n",
    "\n",
    "#         write_center_x = min(self.grid[0] - self.write_size[0] / 2, \n",
    "#                              max(self.write_size[0] / 2, \n",
    "#                                  round((xy[0] - self.mins[0]) / self.scale)))\n",
    "#         write_center_y = min(self.grid[1] - self.write_size[1] / 2, \n",
    "#                              max(self.write_size[1] / 2, \n",
    "#                                  round((xy[0] - self.mins[1]) / self.scale)))\n",
    "        \n",
    "#         xy = tensor([[xy[0] - (write_center_x * self.scale + self.mins[0]), \n",
    "#                       xy[1] - (write_center_y * self.scale + self.mins[1])]])\n",
    "        \n",
    "#         #grid_memory = torch.zeros(self.D, self.grid[0], self.grid[1])\n",
    "#         img = img.unsqueeze(0)\n",
    "#         #input_encode = F.relu(torch.cat((self.xy_write_encode(xy), self.img_write_encode(img)), 1))\n",
    "#         input_encode = F.relu(self.img_write_encode(img))\n",
    "#         start_x = int(write_center_x - self.write_size[0] / 2)\n",
    "#         start_y = int(write_center_y - self.write_size[1] / 2)\n",
    "        \n",
    "#         local_mem = grid_mem[:, start_x:start_x+self.write_size[0], start_y:start_y+self.write_size[0]].unsqueeze(0)\n",
    "\n",
    "    \n",
    "#         full_in = torch.cat((local_mem, input_encode), 1)\n",
    "#         out = F.relu(self.write_combine(full_in))\n",
    "#         out = self.write_final(out)[0]\n",
    "#         grid_mem[:-1, start_x:start_x+self.write_size[0], start_y:start_y+self.write_size[0]] = out\n",
    "#         grid_mem[-1, start_x:start_x+self.write_size[0], start_y:start_y+self.write_size[0]] = 1\n",
    "#         return grid_mem\n",
    "    \n",
    "    def forward_write(self, grid_mem, xy, img):\n",
    "        # Working in pixel space\n",
    "        pixel_x = int((xy[0] - self.mins[0]) * self.pixel_scale)\n",
    "        pixel_y = int((xy[1] - self.mins[1]) * self.pixel_scale)\n",
    "        start_x = min(self.grid[0] - self.write_size[0], \n",
    "                      max(0, \n",
    "                          int((xy[0] - img.shape[-1] / 2. / self.pixel_scale - self.mins[0]) * self.grid_scale)))\n",
    "        start_y = min(self.grid[1] - self.write_size[1], \n",
    "                      max(0, \n",
    "                          int((xy[1] - img.shape[-1] / 2. / self.pixel_scale - self.mins[1]) * self.grid_scale)))\n",
    "        local_start_x = pixel_x - int(start_x * self.pixel_scale / self.grid_scale) - int(img.shape[1] / 2)\n",
    "        local_start_y = pixel_y - int(start_y * self.pixel_scale / self.grid_scale) - int(img.shape[2] / 2)\n",
    "\n",
    "        out = torch.zeros(1, img.shape[0] + 1, int(self.write_size[0] * self.pixel_scale / self.grid_scale), \n",
    "                                int(self.write_size[1] * self.pixel_scale / self.grid_scale)).to(device)\n",
    "        \n",
    "        if local_start_x < 0:\n",
    "            img = img[:, -local_start_x:, :]\n",
    "            local_start_x = 0\n",
    "        if local_start_x+img.shape[1] > out.shape[2]:\n",
    "            over = local_start_x + img.shape[1] - out.shape[2]\n",
    "            img = img[:, :-over]\n",
    "\n",
    "        if local_start_y < 0:\n",
    "            img = img[:, :, -local_start_y:]\n",
    "            local_start_y = 0\n",
    "        if local_start_y+img.shape[2] > out.shape[3]:\n",
    "            over = local_start_y + img.shape[2] - out.shape[3]\n",
    "            img = img[:, :, :-over]\n",
    "        with torch.no_grad():\n",
    "            local_start_x = int(local_start_x)\n",
    "            local_start_y = int(local_start_y)\n",
    "            out[0][:-1, local_start_x:local_start_x+img.shape[1], local_start_y:local_start_y+img.shape[2]] = img\n",
    "            out[0][-1][local_start_x:local_start_x+img.shape[1], local_start_y:local_start_y+img.shape[2]] = 1.    \n",
    "        input_encode = F.relu(self.img_write_encode(out), inplace=True)\n",
    "        local_mem = grid_mem[:, start_x:start_x+self.write_size[0], start_y:start_y+self.write_size[1]].unsqueeze(0)\n",
    "        full_in = torch.cat((local_mem, input_encode), 1)\n",
    "        out = F.relu(self.write_final(F.relu(self.write_combine(full_in), inplace=True)))\n",
    "        #out = F.relu(self.write_final(out)[0], inplace=True)\n",
    "        grid_mem[:-1, start_x:start_x+self.write_size[0], start_y:start_y+self.write_size[1]] = out\n",
    "        grid_mem[-1, start_x:start_x+self.write_size[0], start_y:start_y+self.write_size[1]] = 1\n",
    "        return grid_mem\n",
    "    \n",
    "    \n",
    "    def forward_write_seq(self, xys, imgs):\n",
    "        assert len(xys) == len(imgs)\n",
    "        grid_mem = torch.zeros(self.D + 1, self.grid[0], self.grid[1]).to(device)\n",
    "        for i in range(len(xys)):\n",
    "            grid_mem = self.forward_write(grid_mem, xys[i], imgs[i])\n",
    "        return grid_mem\n",
    "    \n",
    "    def forward_2_batch(self, mem_embed, xys):\n",
    "\n",
    "        x1 = F.relu(self.fc_xy1(xys))\n",
    "        x2 = F.relu(mem_embed.to(device))\n",
    "        x2 = torch.repeat_interleave(x2,x1.shape[0]).reshape([x2.shape[1],x1.shape[0]]).t()\n",
    "        x = torch.cat((x2, x1),1)\n",
    "        y = F.relu(self.dropout(self.common_1(x)))\n",
    "        y = F.relu(self.dropout(self.common_2(y)))\n",
    "        y = F.relu(self.common_3(y))\n",
    "        y1 = (self.final(y))\n",
    "\n",
    "        return torch.cat((y1, -y1),1)\n",
    "    \n",
    "    def forward_map_decode(self, grid_mem):\n",
    "        scores = self.map_decoder(grid_mem)\n",
    "        return torch.cat((scores, -scores), 1)\n",
    "\n",
    "    def train_K_decoder(self, imgs_in, xy_in, label_maps, K=350, min_seq_len=3, max_seq_len=10, \n",
    "                         max_epochs=10000, holdout=0, outfile=None):\n",
    "        print(\"starting training on prev\")\n",
    "        start = time.time()\n",
    "        rooms = range(K)\n",
    "        bs = 128\n",
    "        curr_hist = []\n",
    "        acc_hist = []\n",
    "        \n",
    "        room_data = []\n",
    "        for r in rooms:\n",
    "            for seq_len in range(min_seq_len, min(max_seq_len + 1, imgs_in[r].shape[0])):\n",
    "                room_data.append([r, seq_len])\n",
    "        room_data = np.array(room_data, dtype=int)\n",
    "        np.random.shuffle(room_data)\n",
    "        room_data = room_data[:int(len(room_data) * (1 - holdout))]\n",
    "        \n",
    "        print('total training data points: ', len(room_data))\n",
    "        for epoch in range(max_epochs):\n",
    "            if epoch % 100 == 99 and outfile:\n",
    "                torch.save(self.state_dict(), outfile + str(epoch+1) + 'ep.pth')\n",
    "            self.train()           \n",
    "            np.random.shuffle(room_data)\n",
    "                 \n",
    "            seq_images = []\n",
    "            j = 0\n",
    "            for r, seq_len in room_data:\n",
    "                #if j==0: print(r, seq_len, pred_idx)\n",
    "                element_idxs = np.random.choice(30, \n",
    "                                                seq_len, replace=False)\n",
    "                seq_images = imgs_in[r][element_idxs]\n",
    "                \n",
    "                seq_xy = xy_in[r][element_idxs]\n",
    "                \n",
    "#unsqueezes state,forward expects map,grid_mem initialized without batch axis                \n",
    "                pred = self.forward_map_decode(self.forward_write_seq(seq_xy, seq_images).unsqueeze(0))\n",
    "\n",
    "                loss_function = nn.CrossEntropyLoss()#weight=tensor([.25, 1.5]))\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "#                 pred = self.forward_2_batch(self.embedding, xy_list)\n",
    "                temp = self.sm(pred)[:,1]>0.5 #1x108x108\n",
    "                correct = (temp[0].long() == label_maps[r]) \n",
    "                acc = (float(torch.sum(correct))/(correct.shape[0] * correct.shape[1]))\n",
    "\n",
    "                loss = loss_function(pred, label_maps[r].unsqueeze(0))  # torch.tensor(1,dtype = torch.long))\n",
    "\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                self.optimizer.step()\n",
    "                curr_hist.append(float(loss.data))\n",
    "                acc_hist.append(acc)\n",
    "                j += 1\n",
    "                if j % 1000 == 0:\n",
    "                    print(curr_hist[-1], acc)\n",
    "            \n",
    "            if epoch % 1 == 0:\n",
    "                vl, va = validate(self, range(min_seq_len, max_seq_len+1))\n",
    "                print('\\r epoch %d : trainloss %.4f  trainacc %.4f  valloss %.4f  valacc %.4f  time %.2f' % \n",
    "                          (epoch + 1, np.mean(curr_hist), np.mean(acc_hist), vl, va, time.time() - start))\n",
    "            \n",
    "            #print(np.mean(curr_hist))\n",
    "                hist.append(np.mean(curr_hist))\n",
    "                val_hist.append(vl)\n",
    "                curr_hist = []\n",
    "                acc_hist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, seq_range, reps=5):\n",
    "        room_data = []\n",
    "        rooms = range(350, 400)\n",
    "        for r in rooms:\n",
    "            for seq_len in seq_range:\n",
    "                room_data.append([r, seq_len])\n",
    "        losses = []\n",
    "        accs = []  \n",
    "        for _ in range(reps):\n",
    "            #print(_)\n",
    "            model.eval()\n",
    "            np.random.shuffle(room_data)\n",
    "\n",
    "            for r, seq_len in room_data:\n",
    "                #if j==0: print(r, seq_len, pred_idx)\n",
    "                element_idxs = np.random.choice(range(30), \n",
    "                                                seq_len, replace=False)\n",
    "                \n",
    "                seq_images = imgs_in_f[r][element_idxs]\n",
    "                aug_xy = np.array(xc)/100\n",
    "                seq_xy = aug_xy[r][element_idxs]\n",
    "                pred = model.forward_map_decode(model.forward_write_seq(seq_xy, seq_images).unsqueeze(0))\n",
    "\n",
    "                loss_function = nn.CrossEntropyLoss()\n",
    "                \n",
    "                pred_class = model.sm(pred)[:,1]>0.5\n",
    "                #print(pred_class.shape)\n",
    "                coarse_maps = torch.tensor(true_maps,dtype = torch.long,device=device)\n",
    "                correct = (pred_class[0].long() == coarse_maps[r])\n",
    "                acc = (float(torch.sum(correct))/(correct.shape[0] * correct.shape[1]))\n",
    "\n",
    "                loss = loss_function(pred, coarse_maps[r].unsqueeze(0))  # torch.tensor(1,dtype = torch.long))\n",
    "                accs.append(acc)\n",
    "                losses.append(float(loss.data))\n",
    "        return np.mean(losses), np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in_f = tensor(np.stack(imgs_in)).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training on prev\n",
      "total training data points:  2800\n",
      "0.36324572563171387 0.8547\n",
      "0.4495173692703247 0.7954\n",
      " epoch 1 : trainloss 0.3331  trainacc 0.8607  valloss 0.2898  valacc 0.8816  time 1063.71\n",
      "0.27220606803894043 0.8806\n",
      "0.26440078020095825 0.8722\n",
      " epoch 2 : trainloss 0.2736  trainacc 0.8900  valloss 0.2648  valacc 0.8933  time 2122.86\n",
      "0.19234611093997955 0.9223\n",
      "0.26507169008255005 0.8749\n",
      " epoch 3 : trainloss 0.2621  trainacc 0.8957  valloss 0.2540  valacc 0.8987  time 3183.43\n",
      "0.20601892471313477 0.9276\n",
      "0.28386372327804565 0.8869\n",
      " epoch 4 : trainloss 0.2523  trainacc 0.8998  valloss 0.2511  valacc 0.9001  time 4245.11\n",
      "0.28985661268234253 0.8857\n",
      "0.2801658809185028 0.9056\n",
      " epoch 5 : trainloss 0.2478  trainacc 0.9019  valloss 0.2627  valacc 0.8951  time 5308.58\n",
      "0.31663191318511963 0.8737\n",
      "0.21613159775733948 0.9128\n",
      " epoch 6 : trainloss 0.2444  trainacc 0.9036  valloss 0.2540  valacc 0.8995  time 6357.79\n",
      "0.20246168971061707 0.9189\n",
      "0.20466546714305878 0.9012\n",
      " epoch 7 : trainloss 0.2426  trainacc 0.9044  valloss 0.2411  valacc 0.9047  time 7406.14\n",
      "0.19556720554828644 0.9239\n",
      "0.19860216975212097 0.921\n",
      " epoch 8 : trainloss 0.2393  trainacc 0.9060  valloss 0.2429  valacc 0.9036  time 8450.16\n",
      "0.16436098515987396 0.9383\n",
      "0.27552667260169983 0.8983\n",
      " epoch 9 : trainloss 0.2371  trainacc 0.9071  valloss 0.2433  valacc 0.9037  time 9483.59\n",
      "0.15699997544288635 0.9401\n",
      "0.32352718710899353 0.8647\n",
      " epoch 10 : trainloss 0.2348  trainacc 0.9079  valloss 0.2351  valacc 0.9074  time 10522.43\n",
      "0.13741587102413177 0.9566\n",
      "0.1814545840024948 0.924\n",
      " epoch 11 : trainloss 0.2339  trainacc 0.9085  valloss 0.2338  valacc 0.9084  time 11548.63\n",
      "0.2580520808696747 0.8927\n",
      "0.22535957396030426 0.9074\n",
      " epoch 12 : trainloss 0.2331  trainacc 0.9088  valloss 0.2305  valacc 0.9096  time 12576.92\n",
      "0.1753232628107071 0.9366\n",
      "0.18244148790836334 0.9196\n",
      " epoch 13 : trainloss 0.2295  trainacc 0.9103  valloss 0.2334  valacc 0.9086  time 13603.94\n",
      "0.2313053458929062 0.9153\n",
      "0.44613271951675415 0.811\n",
      " epoch 14 : trainloss 0.2300  trainacc 0.9103  valloss 0.2331  valacc 0.9084  time 14643.79\n",
      "0.2601458728313446 0.903\n",
      "0.16817468404769897 0.934\n",
      " epoch 15 : trainloss 0.2284  trainacc 0.9111  valloss 0.2339  valacc 0.9076  time 15661.70\n",
      "0.18611587584018707 0.9292\n",
      "0.2624652683734894 0.896\n",
      " epoch 16 : trainloss 0.2277  trainacc 0.9112  valloss 0.2304  valacc 0.9096  time 16682.63\n",
      "0.2853042483329773 0.8898\n",
      "0.1529163122177124 0.9367\n"
     ]
    }
   ],
   "source": [
    "hist = []\n",
    "val_hist = []\n",
    "\n",
    "A=GVM()\n",
    "A.to(device)\n",
    "A.train_K_decoder(imgs_in_f,xc/100,torch.tensor(np.stack(true_maps),dtype = torch.long,device = device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(A.state_dict(), '/home/azav/gvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_xy = np.array(xc)/100\n",
    "seq_xy = aug_xy[35][0:8]\n",
    "seq_images = tensor(np.stack(imgs_in_1)[35][0:8])\n",
    "pred = A.forward_map_decode(torch.stack(A.forward_write_seq(seq_xy, seq_images)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=(A.sm(pred)[:,1]>0.5).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(prediction[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
