{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active-Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "device = \"cuda:1\"\n",
    "\n",
    "# c = np.random.randn(3,2)\n",
    "# c=np.clip(a_min=-2.0,a_max=2.0,a=c)\n",
    "def labels(x,c):\n",
    "    \n",
    "    d=c-x\n",
    "    d=np.clip(a_min=-0.5,a_max=0.5,a=d)-d\n",
    "    \n",
    "    for i in d:\n",
    "        if i[0]==0 and i[1]==0:\n",
    "             return(1)\n",
    "    else: return(0.2)\n",
    "    \n",
    "def labels_diff_shape(x,c):\n",
    "    \n",
    "    d=c-x\n",
    "    d1=np.clip(a_min=-0.5,a_max=0.5,a=d)-d\n",
    "    d1_prox = []\n",
    "    d2=np.clip(a_min=-0.5,a_max=0.9,a=d)-d\n",
    "    d2_prox = []\n",
    "\n",
    "    for i in d1:\n",
    "        if i[0]==0 and i[1]==0:\n",
    "             d1_prox.append(1)\n",
    "        else: d1_prox.append(0)\n",
    "    for i in d2:\n",
    "        if i[0]==0 and i[1]==0:\n",
    "             d2_prox.append(1)\n",
    "        else: d2_prox.append(0)\n",
    "\n",
    "    if (d1_prox[0]==1 and d2_prox[0]==1) or (d1_prox[1]==1) or (d2_prox[0]==1):\n",
    "        return(1)\n",
    "    else: return(0.2)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create True Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_MIN, X_MAX, Y_MIN, Y_MAX = -2.5, 2.5, -2.5, 2.5\n",
    "TABLE_X_LENGTH, TABLE_Y_LENGTH = 1, 1\n",
    "SOFA_X_LENGTH, SOFA_Y_LENGTH = 1, 1\n",
    "map_scale = 32\n",
    "\n",
    "def random_table_sofa_centers(n_tables, n_sofas):\n",
    "    \"\"\"\n",
    "    Generate random table center locations within the bounds of the room and not\n",
    "    overlapping with each other.\n",
    "\n",
    "    :param n_tables: The number of table centers to generate\n",
    "    :return: The table centers in a list of [x, y] pairs\n",
    "    \"\"\"\n",
    "    def is_overlap(table_centers, sofa_centers, new_x, new_y, new_x_len, new_y_len):\n",
    "        overlap = False\n",
    "        for x, y in table_centers:\n",
    "            if (abs(x - new_x) < (TABLE_X_LENGTH + new_x_len) / 2 and \n",
    "                abs(y - new_y) < (TABLE_Y_LENGTH + new_y_len) / 2):\n",
    "                overlap = True\n",
    "        for x, y in sofa_centers:\n",
    "            if (abs(x - new_x) < (SOFA_X_LENGTH + new_x_len) / 2 and \n",
    "                abs(y - new_y) < (SOFA_Y_LENGTH + new_y_len) / 2):\n",
    "                overlap = True\n",
    "        return overlap\n",
    "\n",
    "    table_centers, sofa_centers = [], []\n",
    "    for _ in range(n_tables):\n",
    "        new_x = X_MIN + TABLE_X_LENGTH / 2 + np.random.rand() * (X_MAX - X_MIN - TABLE_X_LENGTH)\n",
    "        new_y = Y_MIN + TABLE_Y_LENGTH / 2 + np.random.rand() * (Y_MAX - Y_MIN - TABLE_Y_LENGTH)\n",
    "        while is_overlap(table_centers, sofa_centers, new_x, new_y, TABLE_X_LENGTH, TABLE_Y_LENGTH):\n",
    "            new_x = X_MIN + TABLE_X_LENGTH / 2 + np.random.rand() * (X_MAX - X_MIN - TABLE_X_LENGTH)\n",
    "            new_y = Y_MIN + TABLE_Y_LENGTH / 2 + np.random.rand() * (Y_MAX - Y_MIN - TABLE_Y_LENGTH)\n",
    "        table_centers.append([new_x, new_y])\n",
    "    for _ in range(n_sofas):\n",
    "        new_x = X_MIN + SOFA_X_LENGTH / 2 + np.random.rand() * (X_MAX - X_MIN - SOFA_X_LENGTH)\n",
    "        new_y = Y_MIN + SOFA_Y_LENGTH / 2 + np.random.rand() * (Y_MAX - Y_MIN - SOFA_Y_LENGTH)\n",
    "        while is_overlap(table_centers, sofa_centers, new_x, new_y, SOFA_X_LENGTH, SOFA_Y_LENGTH):\n",
    "            new_x = X_MIN + SOFA_X_LENGTH / 2 + np.random.rand() * (X_MAX - X_MIN - SOFA_X_LENGTH)\n",
    "            new_y = Y_MIN + SOFA_Y_LENGTH / 2 + np.random.rand() * (Y_MAX - Y_MIN - SOFA_Y_LENGTH)\n",
    "        sofa_centers.append([new_x, new_y])\n",
    "    return table_centers, sofa_centers\n",
    "room_center=[]\n",
    "for i in range(200):\n",
    "    temp = random_table_sofa_centers(5,0)\n",
    "    room_center.append(temp[0])\n",
    "c_rooms = np.stack(room_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Images for input\n",
    "### Using ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc=np.random.randint(low=-150,high=150,size=(200,30,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from labeller\n",
    "# imgs_in=[]\n",
    "# for i,room in enumerate(xc):\n",
    "#     temp = []\n",
    "#     for j in room:\n",
    "#         temp_img=[]\n",
    "#         temp_x = np.arange(j[0]-100,j[0]+100,5)\n",
    "#         temp_y = np.arange(j[1]-100,j[1]+100,5)\n",
    "#         x,y=np.meshgrid(temp_x,temp_y)\n",
    "#         for k in np.append(x.reshape(1,1600).T,y.reshape(1,1600).T,1):\n",
    "#             temp_img.append(labels(k/100,c_rooms[i]))\n",
    "#         temp_img=np.array(temp_img)\n",
    "#         temp.append(temp_img.reshape(40,40))\n",
    "#     imgs_in.append(temp)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_image_from_truth(true_map,xy):\n",
    "    xy[0]+=2.5\n",
    "    xy[1]+=2.5\n",
    "    xy[0]/=0.05\n",
    "    xy[1]/=0.05  \n",
    "    a = np.int(np.floor(xy[0]))\n",
    "    b = np.int(np.floor(xy[1]))\n",
    "    return(true_map[a-20:a+20,b-20:b+20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Padded input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For GVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_images(image,xy):\n",
    "    c_x = xy[0]/0.05+50\n",
    "    c_y = xy[1]/0.05+50\n",
    "    x_0 =int(c_x%10)\n",
    "    y_0 = int(c_y%10)\n",
    "    image_new = np.zeros((2,50,50))\n",
    "    image_new[0,x_0:x_0+40,y_0:y_0+40] = 1\n",
    "    image_new[1,x_0:x_0+40,y_0:y_0+40] = image\n",
    "    return(image_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_images_LSTM(image,xy):\n",
    "    c_x = xy[0]/0.05+50\n",
    "    c_y = xy[1]/0.05+50\n",
    "    x_0 = int(c_x//10)*10\n",
    "    y_0 = int(c_y//10)*10\n",
    "    \n",
    "    image_new = np.zeros((2,100,100))\n",
    "    image_new[0,x_0-20:x_0+30,y_0-20:y_0+30] = image[0]\n",
    "    image_new[1,x_0-20:x_0+30,y_0-20:y_0+30] = image[1]\n",
    "    return(image_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create True Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_true_map(centres):\n",
    "    #select uniformly\n",
    "    xm=np.arange(-2.5,2.5,0.05)\n",
    "    ym=np.arange(-2.5,2.5,0.05)\n",
    "    xm,ym = np.meshgrid(xm,ym)\n",
    "    map_samp = np.append(xm.reshape(1,10000).T,ym.reshape(1,10000).T,1)\n",
    "    #label Uniform Points\n",
    "    true_map = []\n",
    "    for j in range(10000):\n",
    "        true_map.append(labels(map_samp[j],centres))\n",
    "    return(np.array(true_map).reshape(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_maps = []\n",
    "for i in c_rooms:\n",
    "    true_maps.append(create_true_map(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_in=[]\n",
    "for i,room in enumerate(xc):\n",
    "    temp = []\n",
    "    for j in room:\n",
    "        temp_img=inp_image_from_truth(true_maps[i],j/100)\n",
    "        temp.append(temp_img)\n",
    "    imgs_in.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot True Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faeff84d128>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fafd03ecf98>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(true_maps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pad input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs_in_1 = deepcopy(imgs_in)\n",
    "imgs_in_2 = deepcopy(imgs_in)\n",
    "for rooms in range(200):\n",
    "    for j,image in enumerate(imgs_in[rooms]):\n",
    "        image = pad_images(image,xc[rooms][j]/100)\n",
    "        imgs_in_1[rooms][j] = image\n",
    "        imgs_in_2[rooms][j] = pad_images_LSTM(image,xc[rooms][j]/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=(int((xc[0][0][0]/5+50)//10)*10,int((xc[0][0][1]/5+50)//10)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faeff6f2fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAACuxJREFUeJzt3V+IXPd5h/HnW/3NH4Lt1DaqZGoXRLEvGpkursC9KHJMVSdEunDBJi26EOgmBYcGUqWFQqAX8U2cm96I2ETQEDt1AhImUIQsEwpFthw7iR2RSDG0ERZWSyySFKpYyduLPTaLvPLO7s7Mzvp9PrDMnN+e8Xkx++icMzuWU1VI6uV31noASdNn+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDqwo/yd4kP05yPsnhcQ0labKy0k/uJdkA/AS4H7gAvAA8XFU/ut5rNmdLbeVDKzqepKX9H//Lr+tKltpv4yqOcQ9wvqpeA0jyJLAPuG74W/kQf5L7VnFISe/ldJ0cab/VXOpvB362YPvCsCZpxq3mjL/Y5cS77huSHAIOAWzlg6s4nKRxWc0Z/wJw24LtHcDr1+5UVUeqaq6q5jaxZRWHkzQuqwn/BWBnkjuSbAYeAo6PZyxJk7TiS/2quprkb4B/AzYAT1TVq2ObTNLErOYen6r6DvCdMc0iaUr85J7U0KrO+OvZ1T1/vNYjSMu28dkXx/LP8YwvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkNLhp/kiSSXkryyYO2mJCeSnBseb5zsmJLGaZQz/teAvdesHQZOVtVO4OSwLWmdWDL8qvou8PNrlvcBR4fnR4H9Y55L0gSt9B7/1qq6CDA83jK+kSRN2sZJHyDJIeAQwFY+OOnDSRrBSs/4byTZBjA8XrrejlV1pKrmqmpuE1tWeDhJ47TS8I8DB4bnB4Bj4xlH0jSM8uu8bwD/AfxhkgtJDgJfAu5Pcg64f9iWtE4seY9fVQ9f51v3jXkWSVPiJ/ekhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGlgw/yW1JTiU5m+TVJI8M6zclOZHk3PB44+THlTQOo5zxrwKfq6o7gd3AZ5LcBRwGTlbVTuDksC1pHVgy/Kq6WFXfG57/EjgLbAf2AUeH3Y4C+yc1pKTxWtY9fpLbgbuB08CtVXUR5v9wAG4Z93CSJmPk8JN8GPgW8Nmq+sUyXncoyZkkZ97iykpmlDRmI4WfZBPz0X+9qr49LL+RZNvw/W3ApcVeW1VHqmququY2sWUcM0tapVHe1Q/wOHC2qr684FvHgQPD8wPAsfGPJ2kSNo6wz73AXwM/TPLysPb3wJeAbyY5CPwX8JeTGVHSuC0ZflX9O5DrfPu+8Y4jaRr85J7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtTQKP9Djfelk//y+FqPMLL7/urgWo+g9xnP+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNbRk+Em2Jnk+yfeTvJrki8P6HUlOJzmX5Kkkmyc/rqRxGOWMfwXYU1UfA3YBe5PsBh4FHquqncCbgB8ol9aJJcOveb8aNjcNXwXsAZ4e1o8C+ycyoaSxG+keP8mGJC8Dl4ATwE+By1V1ddjlArB9MiNKGreRwq+q31TVLmAHcA9w52K7LfbaJIeSnEly5i2urHxSSWOzrHf1q+oy8BywG7ghydv/Pf8O4PXrvOZIVc1V1dwmtqxmVkljMsq7+jcnuWF4/gHg48BZ4BTw4LDbAeDYpIaUNF6j/A0824CjSTYw/wfFN6vqmSQ/Ap5M8k/AS8D6+SttpOaWDL+qfgDcvcj6a8zf70taZ/zkntSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1NDI4SfZkOSlJM8M23ckOZ3kXJKnkmye3JiSxmk5Z/xHgLMLth8FHquqncCbwMFxDiZpckYKP8kO4BPAV4ftAHuAp4ddjgL7JzGgpPEb9Yz/FeDzwG+H7Y8Cl6vq6rB9Adi+2AuTHEpyJsmZt7iyqmEljceS4Sf5JHCpql5cuLzIrrXY66vqSFXNVdXcJrascExJ47RxhH3uBT6V5AFgK/AR5q8AbkiycTjr7wBen9yYksZpyTN+VX2hqnZU1e3AQ8CzVfVp4BTw4LDbAeDYxKaUNFar+T3+3wF/m+Q88/f8j49nJEmTNsql/juq6jngueH5a8A94x9J0qT5yT2poWWd8d9P/vz3dq31CCPbyItL7yQtg2d8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caSlVN72DJfwP/Cfwu8D9TO/DqrKdZYX3Nu55mhfUx7+9X1c1L7TTV8N85aHKmquamfuAVWE+zwvqadz3NCutv3vfipb7UkOFLDa1V+EfW6LgrsZ5mhfU173qaFdbfvNe1Jvf4ktaWl/pSQ1MNP8neJD9Ocj7J4WkeexRJnkhyKckrC9ZuSnIiybnh8ca1nPFtSW5LcirJ2SSvJnlkWJ/VebcmeT7J94d5vzis35Hk9DDvU0k2r/Wsb0uyIclLSZ4Ztmd21uWaWvhJNgD/DPwFcBfwcJK7pnX8EX0N2HvN2mHgZFXtBE4O27PgKvC5qroT2A18Zvj3OavzXgH2VNXHgF3A3iS7gUeBx4Z53wQOruGM13oEOLtge5ZnXZZpnvHvAc5X1WtV9WvgSWDfFI+/pKr6LvDza5b3AUeH50eB/VMd6jqq6mJVfW94/kvmf0C3M7vzVlX9atjcNHwVsAd4elifmXmT7AA+AXx12A4zOutKTDP87cDPFmxfGNZm3a1VdRHmYwNuWeN53iXJ7cDdwGlmeN7h0vll4BJwAvgpcLmqrg67zNLPxFeAzwO/HbY/yuzOumzTDD+LrPkrhVVK8mHgW8Bnq+oXaz3Pe6mq31TVLmAH81eAdy6223SnercknwQuVdWLC5cX2XXNZ12pjVM81gXgtgXbO4DXp3j8lXojybaquphkG/Nnq5mQZBPz0X+9qr49LM/svG+rqstJnmP+vYkbkmwczqSz8jNxL/CpJA8AW4GPMH8FMIuzrsg0z/gvADuHd0Y3Aw8Bx6d4/JU6DhwYnh8Ajq3hLO8Y7jkfB85W1ZcXfGtW5705yQ3D8w8AH2f+fYlTwIPDbjMxb1V9oap2VNXtzP+cPltVn2YGZ12xqpraF/AA8BPm7+3+YZrHHnG+bwAXgbeYv0I5yPy93Ung3PB401rPOcz6p8xfav4AeHn4emCG5/0j4KVh3leAfxzW/wB4HjgP/CuwZa1nvWbuPwOeWQ+zLufLT+5JDfnJPakhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5ca+n+NaxBWZLoDdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faeff8960f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_in_1[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faeff659438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAACwlJREFUeJzt3VGonPWZx/Hvb09irZSiSaPEJGxcyC560UY4iOBeLLZi1pYmFy4opeQikJsWLC107S4sFPai3tTe7E2o0lyUatcWFCmIpEpZWKKn1braUJMKuw0Gk7VK213WNumzF+dVzsaTnsk5M3Pm7PP9wDDzvvMO/wc537zvzBmTVBWSevmT9R5A0vQZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtTQmsJPsi/Jz5OcSnL/uIaSNFlZ7Tf3kswBrwJ3AKeB54F7q+pnl3rNR7bM1e5dm1e13uV49aWrJr6GNIv+h//id/VOVjpu0xrWuAU4VVWvASR5BNgPXDL83bs289xTu9aw5GjuvH7vxNeQZtHxOjbScWu51N8B/HLJ9ulhn6QZt5bwl7uceN/7hiSHkywkWTj35oU1LCdpXNYS/mlg6XX7TuD1iw+qqiNVNV9V89u2zq1hOUnjspbwnwf2JLkhyRXAPcAT4xlL0iSt+sO9qjqf5PPAU8Ac8HBVvTK2ySRNzFo+1aeqfgD8YEyzSJoSv7knNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDK4af5OEkZ5O8vGTfliRPJzk53F8z2TEljdMoZ/xvAfsu2nc/cKyq9gDHhm1JG8SK4VfVj4BfXbR7P3B0eHwUODDmuSRN0Grf419XVWcAhvtrxzeSpEmb+Id7SQ4nWUiycO7NC5NeTtIIVhv+G0m2Awz3Zy91YFUdqar5qprftnVulctJGqfVhv8EcHB4fBB4fDzjSJqGUX6d9x3gX4G/SHI6ySHga8AdSU4CdwzbkjaITSsdUFX3XuKpj495FklT4jf3pIYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2po0zQXe/Wlq7jz+r3TXFLSMjzjSw0ZvtTQiuEn2ZXkmSQnkryS5L5h/5YkTyc5OdxfM/lxJY3DKGf888CXqupG4Fbgc0luAu4HjlXVHuDYsC1pA1gx/Ko6U1U/GR7/BjgB7AD2A0eHw44CByY1pKTxuqz3+El2AzcDx4HrquoMLP7hAFw77uEkTcbI4Sf5EPA94AtV9evLeN3hJAtJFn7PO6uZUdKYjRR+ks0sRv/tqvr+sPuNJNuH57cDZ5d7bVUdqar5qprfzAfGMbOkNRrlU/0ADwEnqurrS556Ajg4PD4IPD7+8SRNwijf3LsN+Czwb0leHPb9HfA14LtJDgH/AfzNZEaUNG4rhl9V/wLkEk9/fLzjSJoGv7knNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81NMo/qDE2f/7R/+app15c+UD9H3dev3e9R9D/M57xpYYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2rI8KWGDF9qaMXwk1yZ5LkkP03ySpKvDvtvSHI8yckkjya5YvLjShqHUc747wC3V9XHgL3AviS3Ag8AD1bVHuAt4NDkxpQ0TiuGX4t+O2xuHm4F3A48Nuw/ChyYyISSxm6k9/hJ5pK8CJwFngZ+AbxdVeeHQ04DOyYzoqRxGyn8qrpQVXuBncAtwI3LHbbca5McTrKQZOHcmxdWP6mksbmsT/Wr6m3gWeBW4Ook7/7//DuB1y/xmiNVNV9V89u2zq1lVkljMsqn+tuSXD08/iDwCeAE8Axw93DYQeDxSQ0pabxG+Rt4tgNHk8yx+AfFd6vqySQ/Ax5J8o/AC8BDE5xT0hitGH5VvQTcvMz+11h8vy9pg/Gbe1JDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkMjh59kLskLSZ4ctm9IcjzJySSPJrlicmNKGqfLOePfB5xYsv0A8GBV7QHeAg6NczBJkzNS+El2Ap8EvjlsB7gdeGw45ChwYBIDShq/Uc/43wC+DPxh2N4KvF1V54ft08CO5V6Y5HCShSQL5968sKZhJY3HiuEn+RRwtqp+vHT3MofWcq+vqiNVNV9V89u2zq1yTEnjtGmEY24DPp3kLuBK4MMsXgFcnWTTcNbfCbw+uTEljdOKZ/yq+kpV7ayq3cA9wA+r6jPAM8Ddw2EHgccnNqWksVrL7/H/FvhiklMsvud/aDwjSZq0US7131NVzwLPDo9fA24Z/0iSJs1v7kkNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw1d1t+rv1avvnQVd16/d5pLSlqGZ3ypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caSlVNb7HkHPDvwEeA/5zawmuzkWaFjTXvRpoVNsa8f1pV21Y6aKrhv7doslBV81NfeBU20qywsebdSLPCxpv3j/FSX2rI8KWG1iv8I+u07mpspFlhY827kWaFjTfvJa3Le3xJ68tLfamhqYafZF+Snyc5leT+aa49iiQPJzmb5OUl+7YkeTrJyeH+mvWc8V1JdiV5JsmJJK8kuW/YP6vzXpnkuSQ/Heb96rD/hiTHh3kfTXLFes/6riRzSV5I8uSwPbOzXq6phZ9kDvgn4K+Bm4B7k9w0rfVH9C1g30X77geOVdUe4NiwPQvOA1+qqhuBW4HPDf89Z3Xed4Dbq+pjwF5gX5JbgQeAB4d53wIOreOMF7sPOLFke5ZnvSzTPOPfApyqqteq6nfAI8D+Ka6/oqr6EfCri3bvB44Oj48CB6Y61CVU1Zmq+snw+Dcs/oDuYHbnrar67bC5ebgVcDvw2LB/ZuZNshP4JPDNYTvM6KyrMc3wdwC/XLJ9etg3666rqjOwGBtw7TrP8z5JdgM3A8eZ4XmHS+cXgbPA08AvgLer6vxwyCz9THwD+DLwh2F7K7M762WbZvhZZp+/UlijJB8Cvgd8oap+vd7z/DFVdaGq9gI7WbwCvHG5w6Y71fsl+RRwtqp+vHT3Moeu+6yrNc1/UOM0sGvJ9k7g9Smuv1pvJNleVWeSbGfxbDUTkmxmMfpvV9X3h90zO++7qurtJM+y+NnE1Uk2DWfSWfmZuA34dJK7gCuBD7N4BTCLs67KNM/4zwN7hk9GrwDuAZ6Y4vqr9QRwcHh8EHh8HWd5z/Ce8yHgRFV9fclTszrvtiRXD48/CHyCxc8lngHuHg6biXmr6itVtbOqdrP4c/rDqvoMMzjrqlXV1G7AXcCrLL63+/tprj3ifN8BzgC/Z/EK5RCL7+2OASeH+y3rPecw61+yeKn5EvDicLtrhuf9KPDCMO/LwD8M+/8MeA44Bfwz8IH1nvWiuf8KeHIjzHo5N7+5JzXkN/ekhgxfasjwpYYMX2rI8KWGDF9qyPClhgxfauh/AUC+H7TSlInQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fafd03eca58>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(true_maps[0][t[0]-20:t[0]+30,t[1]-20:t[1]+30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faeff62ccf8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faeff6ab278>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_in_2[0][0][1][t[0]-20:t[0]+30,t[1]-20:t[1]+30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faeff586e10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faeff60c668>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_in_2[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faeff55fcf8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faeff5df780>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs_in[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor(obj):\n",
    "    return torch.tensor(obj, device=device,dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size: (int, int)\n",
    "            Height and width of input tensor as (height, width).\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.height, self.width = input_size\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias        = bias\n",
    "        self.features = nn.Sequential(  # 100x100\n",
    "            nn.Conv2d(2, 8, 5),  # 96x96\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),  # 48x48\n",
    "            nn.Conv2d(8, 16, 7),  # 42x42\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3),  # 14x14\n",
    "            nn.Conv2d(16, 16, 5),  # 10x10\n",
    "        )\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels=self.hidden_dim + self.input_dim,\n",
    "                              out_channels=36,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias),\n",
    "                                    nn.Conv2d(in_channels=36,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias))\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        \n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat([self.features(input_tensor), h_cur], dim=1)  # concatenate along channel axis\n",
    "        \n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1) \n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        \n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "#         return (Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width)).cuda(),\n",
    "#                 Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width)).cuda())\n",
    "        temp = (tensor(Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width))),\n",
    "                tensor(Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width))))\n",
    "        return temp\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=False, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim  = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.height, self.width = input_size\n",
    "        device = \"cuda:1\"\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i-1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_size=(self.height, self.width),\n",
    "                                          input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias).to(device))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor: todo \n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state: todo\n",
    "            None. todo implement stateful\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        # Implement stateful ConvLSTM\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            hidden_state = self._init_hidden(batch_size=input_tensor.size(0))\n",
    "        layer_output_list = []\n",
    "        layer_output_list = []\n",
    "        last_state_list   = []\n",
    "        layer_output_inner_list = []\n",
    "        layer_output_outer_list = []\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            output_outer = []\n",
    "            for t in range(seq_len):\n",
    "\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
    "                                                 cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "                output_outer.append(c)\n",
    "            cur_layer_input = torch.stack(output_inner, dim=1)\n",
    "            \n",
    "            layer_outer = torch.stack(output_outer, dim=1)\n",
    "            layer_output_inner = torch.stack(output_inner, dim=1)\n",
    "            layer_output_inner_list.append(cur_layer_input)\n",
    "            layer_output_outer_list.append(layer_outer)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list   = last_state_list[-1:]\n",
    "\n",
    "        return layer_output_inner_list,layer_output_outer_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                    (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (cell_list): ModuleList(\n",
       "    (0): ConvLSTMCell(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(2, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "        (6): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(26, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(36, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height = 10\n",
    "width = 10\n",
    "channels = 16\n",
    "\n",
    "model = ConvLSTM(input_size=(height, width),\n",
    "                 input_dim=channels,\n",
    "                 hidden_dim=[10],\n",
    "                 kernel_size=(3, 3),\n",
    "                 num_layers=1,\n",
    "                 batch_first=True,\n",
    "                 bias=True,\n",
    "                 return_all_layers=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 30, 2, 100, 100])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(np.stack(imgs_in_2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (cell_list): ModuleList(\n",
       "    (0): ConvLSTMCell(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(2, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "        (6): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(26, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(36, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 10, 10, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model(tensor(np.stack(imgs_in_2))[0].unsqueeze(0))[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_Decoder, self).__init__()\n",
    "        self.map_decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(20, 16, 5, stride=3, padding=2),  # b, 16, 28, 28\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=2),  # b, 8, 53, 53\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=3)  # b, 1, 100, 100\n",
    "        ) \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),weight_decay = 0.0001,  lr=0.001)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "    def forward_map_decode(self, grid_mem):\n",
    "        scores = self.map_decoder(grid_mem)\n",
    "        return torch.cat((scores, -scores), 1)\n",
    "            \n",
    "    \n",
    "    def train_K_decoder(self,model, imgs_in, xy_in, label_maps, K=150, min_seq_len=1, max_seq_len=10, \n",
    "                         max_epochs=200, holdout=0, outfile=None):\n",
    "        print(\"starting training on prev\")\n",
    "        start = time.time()\n",
    "        rooms = range(K)\n",
    "        bs = 128\n",
    "        curr_hist = []\n",
    "        acc_hist = []\n",
    "\n",
    "        room_data = []\n",
    "        for r in rooms:\n",
    "            for seq_len in range(10,11):# range(min_seq_len, min(max_seq_len + 1, imgs_in[r].shape[0])):\n",
    "                room_data.append([r, seq_len])\n",
    "        room_data = np.array(room_data, dtype=int)\n",
    "        np.random.shuffle(room_data)\n",
    "        room_data = room_data[:int(len(room_data) * (1 - holdout))]\n",
    "\n",
    "        print('total training data points: ', len(room_data))\n",
    "        for epoch in range(max_epochs):\n",
    "            if epoch % 100 == 99 and outfile:\n",
    "                torch.save(self.state_dict(), outfile + str(epoch+1) + 'ep.pth')\n",
    "            self.train()           \n",
    "            np.random.shuffle(room_data)\n",
    "\n",
    "            seq_images = []\n",
    "            j = 0\n",
    "            for r, seq_len in room_data:\n",
    "                #if j==0: print(r, seq_len, pred_idx)\n",
    "                element_idxs = np.random.choice(30, \n",
    "                                                seq_len, replace=False)\n",
    "                seq_images = imgs_in[r][element_idxs]\n",
    "\n",
    "                seq_xy = xy_in[r][element_idxs]\n",
    "\n",
    "    #unsqueezes state,forward expects map,grid_mem initialized without batch axis    \n",
    "                h,c,_ = model(seq_images.unsqueeze(0))\n",
    "    #                 print(temp.shape)\n",
    "                pred = self.forward_map_decode(torch.cat((h[0],c[0]),2).squeeze(0))\n",
    "                loss_function = nn.CrossEntropyLoss()#weight=tensor([.25, 1.5]))\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "#                 pred = self.forward_2_batch(self.embedding, xy_list)\n",
    "                temp = self.sm(pred)[:,1]>0.5 #1x108x108\n",
    "\n",
    "                correct = (temp[:][0].long() == torch.stack([label_maps[r]]*seq_len)) \n",
    "                acc = (float(torch.sum(correct))/(correct.shape[0] * correct.shape[1]))\n",
    "#                 loss = loss_function(pred, label_maps[r].unsqueeze(0))  # torch.tensor(1,dtype = torch.long))\n",
    "\n",
    "#                 loss.backward(retain_graph=True)\n",
    "                loss = loss_function(pred,torch.stack([label_maps[r]]*seq_len))\n",
    "                loss.backward(retain_graph=True)\n",
    "                self.optimizer.step()\n",
    "                curr_hist.append(float(loss.data))\n",
    "                acc_hist.append(acc)\n",
    "                j += 1\n",
    "                if j % 1000 == 0:\n",
    "                     print(curr_hist[-1], acc)\n",
    "            \n",
    "            if epoch % 1 == 0:\n",
    "                vl, va = validate(self,model, range(10, 10+1))\n",
    "                print('\\r epoch %d : trainloss %.4f  trainacc %.4f  valloss %.4f  valacc %.4f  time %.2f' % (epoch + 1, np.mean(curr_hist), np.mean(acc_hist), vl, va, time.time() - start))\n",
    "            \n",
    "            #print(np.mean(curr_hist))\n",
    "                hist.append(np.mean(curr_hist))\n",
    "                val_hist.append(vl)\n",
    "                curr_hist = []\n",
    "                acc_hist = []\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(decoder,model, seq_range, reps=5):\n",
    "        room_data = []\n",
    "        rooms = range(150, 200)\n",
    "        for r in rooms:\n",
    "            for seq_len in seq_range:\n",
    "                room_data.append([r, seq_len])\n",
    "        losses = []\n",
    "        accs = []  \n",
    "        for _ in range(reps):\n",
    "            #print(_)\n",
    "            model.eval()\n",
    "            np.random.shuffle(room_data)\n",
    "\n",
    "            for r, seq_len in room_data:\n",
    "                #if j==0: print(r, seq_len, pred_idx)\n",
    "                element_idxs = np.random.choice(range(30), \n",
    "                                                seq_len, replace=False)\n",
    "                seq_images = tensor(np.stack(imgs_in_2)[r][element_idxs])\n",
    "                aug_xy = np.array(xc)/100\n",
    "                seq_xy = aug_xy[r][element_idxs]\n",
    "                \n",
    "                h,c,_ = model(seq_images.unsqueeze(0))\n",
    "                pred = decoder.forward_map_decode(torch.cat((h[0],c[0]),2).squeeze(0))\n",
    "                loss_function = nn.CrossEntropyLoss()\n",
    "                \n",
    "                pred_class = decoder.sm(pred)[:,1]>0.5\n",
    "                #print(pred_class.shape)\n",
    "                coarse_maps = torch.tensor(true_maps,dtype = torch.long,device = device)\n",
    "                correct = (pred_class[:][0].long() == torch.stack([coarse_maps[r]]*seq_len)) \n",
    "                acc = (float(torch.sum(correct))/(correct.shape[0] * correct.shape[1]))\n",
    "\n",
    "                loss = loss_function(pred, torch.stack([coarse_maps[r]]*seq_len))  # torch.tensor(1,dtype = torch.long))\n",
    "                accs.append(acc)\n",
    "                losses.append(float(loss.data))\n",
    "        return np.mean(losses), np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = []\n",
    "val_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_Decoder(\n",
       "  (map_decoder): Sequential(\n",
       "    (0): ConvTranspose2d(20, 16, kernel_size=(5, 5), stride=(3, 3), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): ConvTranspose2d(8, 1, kernel_size=(2, 2), stride=(2, 2), padding=(3, 3))\n",
       "  )\n",
       "  (sm): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=LSTM_Decoder()\n",
    "A.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training on prev\n",
      "total training data points:  150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "A.train_K_decoder(model,tensor(np.stack(imgs_in_2)),xc/100,torch.tensor(np.stack(true_maps),dtype = torch.long,device=device))\n",
    "torch.save(A.state_dict(), '/home/azav/cn_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_images=tensor(np.stack(imgs_in_2[15][0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,c,_ = model(seq_images.unsqueeze(0))\n",
    "pred = A.forward_map_decode(torch.cat((h[0],c[0]),2).squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/home/azav/cn_lstm_100b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=(A.sm(pred)[:,1]>0.5).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prediction[9]*1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
